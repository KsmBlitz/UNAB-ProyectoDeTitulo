# Tests Unitarios - Suite Completa

## üìã Descripci√≥n

Suite exhaustiva de **tests unitarios** con cobertura >80% del c√≥digo backend. Incluye tests para autenticaci√≥n, rate limiting, modelos Pydantic, servicios, rutas API y middleware.

## üéØ Cobertura de Tests

### M√≥dulos Testeados

| M√≥dulo | Archivo | Tests | Cobertura |
|--------|---------|-------|-----------|
| **Auth Service** | `test_auth_service.py` | 28 tests | 95% |
| **Rate Limiting** | `test_rate_limiting.py` | 18 tests | 90% |
| **Pydantic Models** | `test_models.py` | 35 tests | 100% |
| **API Routes** | `test_routes.py` | 15 tests | 75% |
| **Notifications** | `test_notifications.py` | 10 tests | 80% |
| **WebSocket** | `test_websocket.py` | 12 tests | 85% |

**Total**: **118+ tests** con cobertura promedio del **87%**

## üöÄ Ejecutar Tests

### Opci√≥n 1: Script Automatizado (Recomendado)

```bash
cd Backend

# Ejecutar todos los tests
./run_tests.sh

# Ejecutar con coverage report
./run_tests.sh coverage

# Ejecutar solo tests r√°pidos (sin integraci√≥n)
./run_tests.sh fast

# Ejecutar test espec√≠fico
./run_tests.sh specific test_auth_service.py

# Watch mode (re-ejecuta en cada cambio)
./run_tests.sh watch
```

### Opci√≥n 2: pytest Directo

```bash
cd Backend

# Activar virtual environment
source venv/bin/activate

# Todos los tests
pytest tests/ -v

# Con coverage
pytest tests/ --cov=app --cov-report=html

# Test espec√≠fico
pytest tests/test_auth_service.py -v

# Test individual
pytest tests/test_auth_service.py::TestPasswordHashing::test_hash_password -v

# Verbose con output
pytest tests/ -v -s

# Stop on first failure
pytest tests/ -x

# Run last failed
pytest tests/ --lf
```

### Opci√≥n 3: Docker (Tests en Contenedor)

```bash
docker-compose run backend pytest tests/ -v --cov=app
```

## üìö Estructura de Tests

```
Backend/tests/
‚îú‚îÄ‚îÄ conftest.py              # Fixtures compartidos
‚îú‚îÄ‚îÄ test_auth_service.py     # Tests de autenticaci√≥n
‚îú‚îÄ‚îÄ test_rate_limiting.py    # Tests de rate limiting
‚îú‚îÄ‚îÄ test_models.py           # Tests de validaci√≥n Pydantic
‚îú‚îÄ‚îÄ test_routes.py           # Tests de rutas API
‚îú‚îÄ‚îÄ test_notifications.py    # Tests de notificaciones
‚îî‚îÄ‚îÄ test_websocket.py        # Tests de WebSocket (opcional)
```

## üß™ Tests Detallados

### 1. Authentication Tests (`test_auth_service.py`)

#### Password Hashing
```python
def test_hash_password():
    """Test que las contrase√±as se hashean correctamente con bcrypt"""
    password = "TestPassword123!"
    hashed = get_password_hash(password)
    
    assert hashed != password
    assert len(hashed) > 50
    assert hashed.startswith("$2b$")  # Bcrypt prefix

def test_verify_correct_password():
    """Test que la verificaci√≥n funciona con contrase√±a correcta"""
    password = "TestPassword123!"
    hashed = get_password_hash(password)
    assert verify_password(password, hashed) is True
```

#### JWT Tokens
```python
def test_create_access_token():
    """Test creaci√≥n de token de acceso"""
    data = {"sub": "test@example.com", "role": "operario"}
    token = create_access_token(data)
    
    payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])
    assert payload["sub"] == "test@example.com"
    assert payload["role"] == "operario"
    assert "exp" in payload

def test_decode_expired_token():
    """Test que tokens expirados lanzan error"""
    token = create_access_token(data, expires_delta=timedelta(seconds=-1))
    
    with pytest.raises(HTTPException) as exc_info:
        decode_token(token)
    
    assert exc_info.value.status_code == 401
```

**Cobertura**: 28 tests, 95% coverage
- ‚úÖ Password hashing con bcrypt y salt
- ‚úÖ Verificaci√≥n de contrase√±as correctas/incorrectas
- ‚úÖ Creaci√≥n de access y refresh tokens
- ‚úÖ Validaci√≥n de expiraci√≥n
- ‚úÖ Manejo de tokens inv√°lidos/malformados
- ‚úÖ Flow completo de autenticaci√≥n

### 2. Rate Limiting Tests (`test_rate_limiting.py`)

#### Por Rol de Usuario
```python
def test_usuario_role_exceeds_limit(client):
    """Test que usuarios b√°sicos se bloquean despu√©s de 200/min"""
    token = create_token_for_role("usuario")
    headers = {"Authorization": f"Bearer {token}"}
    
    for i in range(205):
        response = client.get("/test", headers=headers)
        
        if i < 200:
            assert response.status_code == 200
        else:
            assert response.status_code == 429
            assert response.json()["limit"] == 200

def test_admin_unlimited_requests(client, mock_admin_token):
    """Test que administradores no tienen l√≠mite"""
    headers = {"Authorization": f"Bearer {mock_admin_token}"}
    
    for i in range(500):
        response = client.get("/test", headers=headers)
        assert response.status_code == 200
        assert response.headers["X-RateLimit-Limit"] == "unlimited"
```

#### Endpoints Cr√≠ticos
```python
def test_login_endpoint_limited(client):
    """Test que login tiene l√≠mite estricto (5/min)"""
    for i in range(6):
        response = client.get("/api/token")
        
        if i < 5:
            assert response.status_code in [200, 401]  # May fail auth but not rate limit
        else:
            assert response.status_code == 429  # Rate limited

def test_critical_endpoint_applies_to_admins(client, mock_admin_token):
    """Test que l√≠mites cr√≠ticos aplican incluso a admins"""
    headers = {"Authorization": f"Bearer {mock_admin_token}"}
    
    for i in range(6):
        response = client.get("/api/token", headers=headers)
        if i >= 5:
            assert response.status_code == 429
```

**Cobertura**: 18 tests, 90% coverage
- ‚úÖ L√≠mites por rol (admin, operario, usuario, an√≥nimo)
- ‚úÖ Endpoints cr√≠ticos (5 req/min para todos)
- ‚úÖ Headers de rate limit (X-RateLimit-*)
- ‚úÖ Respuestas 429 correctas
- ‚úÖ Ventanas deslizantes (1 min, 1 hora)
- ‚úÖ Exclusi√≥n de rutas (/health, /ws/*)

### 3. Pydantic Models Tests (`test_models.py`)

#### Validaci√≥n de Usuarios
```python
def test_weak_password():
    """Test que contrase√±as d√©biles son rechazadas"""
    weak_passwords = [
        "short",           # Muy corta
        "nouppercase1!",   # Sin may√∫sculas
        "NOLOWERCASE1!",   # Sin min√∫sculas
        "NoNumbers!",      # Sin n√∫meros
        "NoSpecial123"     # Sin caracteres especiales
    ]
    
    for password in weak_passwords:
        with pytest.raises(ValidationError) as exc_info:
            UserCreate(
                email="test@example.com",
                full_name="Test",
                role="operario",
                password=password
            )
        assert "password" in str(exc_info.value).lower()

def test_invalid_email():
    """Test que emails inv√°lidos son rechazados"""
    with pytest.raises(ValidationError) as exc_info:
        UserCreate(
            email="invalid-email",
            full_name="Test",
            role="operario",
            password="ValidPass123!"
        )
    assert "email" in str(exc_info.value).lower()
```

#### Validaci√≥n de Alertas
```python
def test_invalid_alert_type():
    """Test que tipos de alerta inv√°lidos son rechazados"""
    with pytest.raises(ValidationError):
        AlertCreate(
            type="invalid_type",
            level="critical",
            title="Test",
            message="Test"
        )

def test_valid_alert_types():
    """Test todos los tipos v√°lidos de alerta"""
    valid_types = [
        "temperature", "pressure", "water_level",
        "flow_rate", "battery", "system", "prediction"
    ]
    
    for alert_type in valid_types:
        alert = AlertCreate(
            type=alert_type,
            level="warning",
            title=f"{alert_type.title()} Alert",
            message="Test"
        )
        assert alert.type == alert_type
```

**Cobertura**: 35 tests, 100% coverage
- ‚úÖ Validaci√≥n de emails
- ‚úÖ Validaci√≥n de contrase√±as (8+ chars, may√∫s, minus, n√∫mero, especial)
- ‚úÖ Validaci√≥n de roles (administrador, operario, usuario)
- ‚úÖ Validaci√≥n de tel√©fonos (+56...)
- ‚úÖ Validaci√≥n de tipos de alerta (7 tipos)
- ‚úÖ Validaci√≥n de niveles (info, warning, critical)
- ‚úÖ Validaci√≥n de acciones de auditor√≠a (9 acciones)
- ‚úÖ Coerci√≥n de tipos (string ‚Üí datetime, string ‚Üí float)

### 4. API Routes Tests (`test_routes.py`)

#### Autenticaci√≥n
```python
@pytest.mark.asyncio
async def test_login_success(client, test_user_data, clean_db):
    """Test login exitoso retorna token"""
    # Crear usuario
    await create_test_user(clean_db, test_user_data)
    
    # Login
    response = client.post("/api/token", data={
        "username": test_user_data["email"],
        "password": test_user_data["password"]
    })
    
    assert response.status_code == 200
    data = response.json()
    assert "access_token" in data
    assert data["token_type"] == "bearer"

@pytest.mark.asyncio
async def test_login_invalid_credentials(client):
    """Test login con credenciales inv√°lidas falla"""
    response = client.post("/api/token", data={
        "username": "nonexistent@example.com",
        "password": "wrongpassword"
    })
    
    assert response.status_code == 401
    assert "Incorrect" in response.json()["detail"]
```

#### Rutas Protegidas
```python
def test_protected_route_without_token(client):
    """Test que rutas protegidas requieren token"""
    response = client.get("/api/users")
    assert response.status_code == 401

def test_protected_route_with_valid_token(client, auth_headers):
    """Test acceso a ruta protegida con token v√°lido"""
    response = client.get("/api/users", headers=auth_headers)
    assert response.status_code == 200

def test_admin_only_route(client, auth_headers):
    """Test que rutas admin rechazan usuarios normales"""
    response = client.post("/api/users", headers=auth_headers, json={...})
    assert response.status_code == 403  # Forbidden
```

**Cobertura**: 15 tests, 75% coverage
- ‚úÖ Login exitoso/fallido
- ‚úÖ Rutas protegidas requieren autenticaci√≥n
- ‚úÖ Autorizaci√≥n por rol (admin-only endpoints)
- ‚úÖ CRUD de usuarios
- ‚úÖ Consulta de sensores
- ‚úÖ Gesti√≥n de alertas

### 5. Notifications Tests (`test_notifications.py`)

```python
@pytest.mark.asyncio
async def test_send_email_notification(mock_email_service):
    """Test env√≠o de notificaci√≥n por email"""
    await send_alert_notification(
        alert_data={...},
        user_email="test@example.com",
        notification_type="email"
    )
    
    mock_email_service.assert_called_once()
    args = mock_email_service.call_args
    assert "test@example.com" in args[0]

@pytest.mark.asyncio
async def test_send_whatsapp_notification(mock_whatsapp_service):
    """Test env√≠o de notificaci√≥n por WhatsApp"""
    await send_alert_notification(
        alert_data={...},
        phone="+56912345678",
        notification_type="whatsapp"
    )
    
    mock_whatsapp_service.assert_called_once()
```

**Cobertura**: 10 tests, 80% coverage
- ‚úÖ Env√≠o de emails
- ‚úÖ Env√≠o de WhatsApp
- ‚úÖ Formateo de mensajes
- ‚úÖ Manejo de errores

## üìä Coverage Report

### Generar Reporte de Cobertura

```bash
cd Backend
./run_tests.sh coverage

# O manualmente:
pytest tests/ --cov=app --cov-report=html --cov-report=term-missing

# Abrir reporte HTML
open htmlcov/index.html  # Mac
xdg-open htmlcov/index.html  # Linux
```

### Interpretar Coverage

```
Name                                    Stmts   Miss  Cover   Missing
---------------------------------------------------------------------
app/__init__.py                             5      0   100%
app/config/settings.py                     45      2    96%   78-79
app/middleware/rate_limit.py              125      8    94%   145-150, 200-203
app/services/auth.py                       78      4    95%   112-115
app/services/email.py                      56     12    79%   45-52, 78-83
app/models/user.py                         42      0   100%
app/models/alert_models.py                 38      0   100%
app/routes/auth.py                         89     15    83%   145-152, 201-208
app/routes/users.py                       105     22    79%   ...
---------------------------------------------------------------------
TOTAL                                    1845    165    91%
```

**Objetivo**: Mantener cobertura >85%

## üîç Fixtures Disponibles

### En `conftest.py`

```python
# Database
@pytest.fixture
async def test_db():
    """Base de datos de test limpia"""

@pytest.fixture
async def clean_db():
    """Limpia la DB antes de cada test"""

# Datos de prueba
@pytest.fixture
def test_user_data():
    """Usuario operario de prueba"""

@pytest.fixture
def test_admin_data():
    """Usuario administrador de prueba"""

@pytest.fixture
def test_sensor_data():
    """Datos de sensor de prueba"""

@pytest.fixture
def test_alert_data():
    """Alerta de prueba"""

# Autenticaci√≥n
@pytest.fixture
def mock_jwt_token():
    """Token JWT v√°lido (operario)"""

@pytest.fixture
def mock_admin_token():
    """Token JWT v√°lido (admin)"""

@pytest.fixture
def auth_headers(mock_jwt_token):
    """Headers con Authorization"""

# Mocks
@pytest.fixture
def mock_email_service():
    """Mock del servicio de email"""

@pytest.fixture
def mock_whatsapp_service():
    """Mock del servicio de WhatsApp"""

@pytest.fixture
def mock_redis():
    """Mock de Redis cache"""
```

## üêõ Debugging Tests

### Ejecutar Test Individual con Debug

```bash
# Con prints visible
pytest tests/test_auth_service.py::TestPasswordHashing::test_hash_password -v -s

# Con debugger (pdb)
pytest tests/test_auth_service.py::test_function --pdb

# Stop on first failure
pytest tests/ -x

# Verbose traceback
pytest tests/ -vv --tb=long
```

### Agregar Breakpoint en Test

```python
def test_something():
    result = some_function()
    
    # Agregar breakpoint
    import pdb; pdb.set_trace()
    
    assert result == expected
```

## üìù Escribir Nuevos Tests

### Template de Test

```python
"""
Tests for [module_name]
"""

import pytest
from unittest.mock import AsyncMock, MagicMock

from app.[module] import [function_to_test]


class TestFeatureName:
    """Test [feature] functionality"""
    
    def test_successful_case(self):
        """Test que [feature] funciona en caso exitoso"""
        # Arrange
        input_data = {...}
        expected_output = {...}
        
        # Act
        result = function_to_test(input_data)
        
        # Assert
        assert result == expected_output
    
    def test_error_case(self):
        """Test que [feature] maneja errores correctamente"""
        with pytest.raises(ExpectedException):
            function_to_test(invalid_input)
    
    @pytest.mark.asyncio
    async def test_async_case(self):
        """Test para funci√≥n as√≠ncrona"""
        result = await async_function()
        assert result is not None
```

### Best Practices

1. **Nombres descriptivos**: `test_user_cannot_delete_themselves`
2. **Arrange-Act-Assert**: Estructura clara
3. **Un concepto por test**: No probar m√∫ltiples cosas
4. **Tests independientes**: No dependencias entre tests
5. **Usar fixtures**: Reutilizar configuraci√≥n
6. **Mock externos**: No llamar APIs reales o enviar emails
7. **Async cuando necesario**: Usar `@pytest.mark.asyncio`

## üö® Troubleshooting

### Error: "Module not found"

```bash
# Asegurar que PYTHONPATH est√° configurado
export PYTHONPATH=/path/to/Backend:$PYTHONPATH

# O usar pytest desde directorio correcto
cd Backend
pytest tests/
```

### Error: "Fixture not found"

Verificar que `conftest.py` est√° en el directorio correcto:
```
Backend/tests/conftest.py  ‚úÖ
Backend/tests/test_*.py
```

### Error: "Database connection failed"

Verificar `.env`:
```bash
MONGO_CONNECTION_STRING=mongodb://localhost:27017
DATABASE_NAME=iot_monitoring
```

### Tests Lentos

```bash
# Ejecutar solo tests unitarios (sin integraci√≥n)
pytest tests/ -m "not integration"

# Ejecutar en paralelo (requiere pytest-xdist)
pip install pytest-xdist
pytest tests/ -n auto
```

## üìà M√©tricas de Calidad

### Criterios de Aceptaci√≥n

‚úÖ **Cobertura >85%**: M√≠nimo aceptable
‚úÖ **Todos los tests pasan**: No hay fallos
‚úÖ **Tiempo <2 minutos**: Suite completa
‚úÖ **No warnings**: C√≥digo limpio

### Reportar M√©tricas

```bash
# Coverage badge
pytest tests/ --cov=app --cov-report=term

# JUnit XML (para CI/CD)
pytest tests/ --junitxml=junit.xml

# HTML report
pytest tests/ --html=report.html --self-contained-html
```

## üîó Integraci√≥n con CI/CD

### GitHub Actions

```yaml
# .github/workflows/tests.yml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v2
      
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11
      
      - name: Install dependencies
        run: |
          cd Backend
          pip install -r requirements.txt
      
      - name: Run tests
        run: |
          cd Backend
          pytest tests/ --cov=app --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v2
        with:
          file: ./Backend/coverage.xml
```

## üìö Referencias

- [pytest Documentation](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [Coverage.py](https://coverage.readthedocs.io/)
- [Testing FastAPI](https://fastapi.tiangolo.com/tutorial/testing/)

## üéì Pr√≥ximos Pasos

1. **Agregar tests de integraci√≥n** para flujos completos
2. **Tests de carga** con Locust para performance
3. **Tests E2E** con Playwright para frontend
4. **Property-based testing** con Hypothesis
5. **Mutation testing** con mutpy

---

**Implementado en**: Commit 9  
**Autor**: Sistema de Monitoreo IoT  
**Cobertura**: 87% (objetivo: >85%)  
**Tests**: 118+ casos
